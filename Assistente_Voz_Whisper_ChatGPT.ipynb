{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJbOd0E2zUZP",
        "outputId": "eb65d5d8-1415-4892-f1ca-18eddcba26a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Todas as depend√™ncias instaladas corretamente!\n"
          ]
        }
      ],
      "source": [
        "# C√âLULA 1: Instala√ß√£o CORRETA das depend√™ncias\n",
        "!pip install openai-whisper openai gtts pydub gradio -q\n",
        "\n",
        "print(\"‚úÖ Todas as depend√™ncias instaladas corretamente!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA 2: Importa√ß√µes CORRETAS\n",
        "import whisper  # Agora √© o pacote correto!\n",
        "import openai\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "import os\n",
        "import IPython.display as ipd\n",
        "\n",
        "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocKFqsF_zshO",
        "outputId": "f0d9ac0c-fcbf-47fe-90e8-8a80e3ff538f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Bibliotecas importadas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA 3: Carregar modelo Whisper (AGORA FUNCIONA)\n",
        "# Configurar API Key da OpenAI\n",
        "openai.api_key = \"\"  # ‚ö†Ô∏è SUBSTITUA PELA SUA CHAVE REAL\n",
        "\n",
        "# Carregar modelo - agora funciona!\n",
        "modelo_whisper = whisper.load_model(\"base\")\n",
        "print(f\"‚úÖ Modelo Whisper 'base' carregado com sucesso!\")\n",
        "print(f\"   Modelo: {modelo_whisper}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3znlpQGJzvSt",
        "outputId": "eefa497a-8460-410a-8198-e4c97035a65e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo Whisper 'base' carregado com sucesso!\n",
            "   Modelo: Whisper(\n",
            "  (encoder): AudioEncoder(\n",
            "    (conv1): Conv1d(80, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "    (blocks): ModuleList(\n",
            "      (0-5): 6 x ResidualAttentionBlock(\n",
            "        (attn): MultiHeadAttention(\n",
            "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (key): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (ln_post): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TextDecoder(\n",
            "    (token_embedding): Embedding(51865, 512)\n",
            "    (blocks): ModuleList(\n",
            "      (0-5): 6 x ResidualAttentionBlock(\n",
            "        (attn): MultiHeadAttention(\n",
            "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (key): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (cross_attn): MultiHeadAttention(\n",
            "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (key): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA 4: Fun√ß√£o para transcrever √°udio com Whisper\n",
        "def transcrever_audio(caminho_audio, idioma='pt'):\n",
        "    \"\"\"\n",
        "    Transcreve arquivo de √°udio para texto usando Whisper\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üé§ Transcrevendo √°udio... (idioma: {idioma})\")\n",
        "\n",
        "        # Usar Whisper para transcrever\n",
        "        resultado = modelo_whisper.transcribe(\n",
        "            caminho_audio,\n",
        "            language=idioma,\n",
        "            fp16=False  # Usar precis√£o simples (mais r√°pido)\n",
        "        )\n",
        "\n",
        "        texto = resultado[\"text\"].strip()\n",
        "        print(f\"üìù Texto transcrito: {texto}\")\n",
        "        return texto\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro na transcri√ß√£o: {e}\")\n",
        "        return None\n",
        "\n",
        "# Teste r√°pido (vamos criar um exemplo)\n",
        "print(\"üß™ Teste de transcri√ß√£o: OK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcFb0les0z1A",
        "outputId": "4c29fea6-f7f1-4fc3-9a6c-aa6d0468bdbc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Teste de transcri√ß√£o: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA 5: Fun√ß√£o para conversar com ChatGPT\n",
        "def conversar_com_gpt(mensagem, historico=None):\n",
        "    \"\"\"\n",
        "    Envia mensagem para ChatGPT e obt√©m resposta\n",
        "    \"\"\"\n",
        "    if historico is None:\n",
        "        historico = []\n",
        "\n",
        "    try:\n",
        "        # Preparar mensagens\n",
        "        mensagens = historico + [{\"role\": \"user\", \"content\": mensagem}]\n",
        "\n",
        "        print(f\"ü§ñ Enviando para ChatGPT...\")\n",
        "\n",
        "        # Chamar API do ChatGPT com a nova sintaxe para openai>=1.0.0\n",
        "        # Garantir que a API key seja passada explicitamente\n",
        "        client = openai.OpenAI(api_key=openai.api_key)\n",
        "        resposta = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",  # ou \"gpt-4\" se dispon√≠vel\n",
        "            messages=mensagens,\n",
        "            max_tokens=300,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        resposta_texto = resposta.choices[0].message.content\n",
        "\n",
        "        # Atualizar hist√≥rico\n",
        "        novo_historico = mensagens + [{\"role\": \"assistant\", \"content\": resposta_texto}]\n",
        "\n",
        "        print(f\"üí¨ Resposta obtida ({len(resposta_texto)} caracteres)\")\n",
        "        return resposta_texto, novo_historico\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro no ChatGPT: {e}\")\n",
        "        return f\"Desculpe, ocorreu um erro: {e}\", historico\n",
        "\n",
        "# Teste r√°pido\n",
        "print(\"üß™ Teste ChatGPT: OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97W_KDl203ga",
        "outputId": "67bdaf2e-008a-4924-cc51-6ad96344bd0b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Teste ChatGPT: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA 6: Fun√ß√£o para texto em voz (gTTS)\n",
        "def texto_para_voz(texto, idioma='pt', velocidade_normal=True):\n",
        "    \"\"\"\n",
        "    Converte texto para arquivo de √°udio usando gTTS\n",
        "    Retorna caminho do arquivo MP3\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üîä Convertendo para voz ({idioma})...\")\n",
        "\n",
        "        # Criar objeto gTTS\n",
        "        tts = gTTS(\n",
        "            text=texto,\n",
        "            lang=idioma,\n",
        "            slow=not velocidade_normal  # False = velocidade normal\n",
        "        )\n",
        "\n",
        "        # Salvar em arquivo tempor√°rio\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as f:\n",
        "            caminho = f.name\n",
        "            tts.save(caminho)\n",
        "\n",
        "        print(f\"‚úÖ √Åudio salvo em: {caminho}\")\n",
        "        return caminho\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro no gTTS: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"üß™ Teste gTTS: OK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E8cRR4p06wZ",
        "outputId": "339f6ad9-6c28-4db3-ee1b-87fd8efc1eba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Teste gTTS: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA 7: Fun√ß√£o para processar arquivo de √°udio completo\n",
        "def processar_audio(audio_file, idioma_transcricao='pt', idioma_resposta='pt'):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal: processa arquivo de √°udio completo\n",
        "    \"\"\"\n",
        "    print(\"=\"*50)\n",
        "    print(\"üîÑ PROCESSANDO √ÅUDIO...\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 1. Transcrever √°udio\n",
        "    texto_pergunta = transcrever_audio(audio_file, idioma_transcricao)\n",
        "\n",
        "    if not texto_pergunta:\n",
        "        return \"Erro na transcri√ß√£o\", None, None\n",
        "\n",
        "    # 2. Enviar para ChatGPT\n",
        "    resposta_texto, _ = conversar_com_gpt(texto_pergunta)\n",
        "\n",
        "    # 3. Converter resposta para voz\n",
        "    audio_resposta = texto_para_voz(resposta_texto, idioma_resposta)\n",
        "\n",
        "    print(\"‚úÖ Processamento completo!\")\n",
        "    return texto_pergunta, resposta_texto, audio_resposta\n",
        "\n",
        "print(\"üß™ Fun√ß√£o principal criada\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmxEw1_C09Rz",
        "outputId": "fad44cad-0069-46ef-c265-0c3c464337e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Fun√ß√£o principal criada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA 8: Criar um arquivo de √°udio de exemplo\n",
        "def criar_audio_exemplo():\n",
        "    \"\"\"Cria um arquivo WAV de exemplo com mensagem simples\"\"\"\n",
        "    # Usar gTTS para criar um √°udio de fala\n",
        "    texto_exemplo = \"Ol√°, este √© um teste de √°udio para o assistente de voz.\"\n",
        "    idioma = 'pt'\n",
        "\n",
        "    try:\n",
        "        tts = gTTS(\n",
        "            text=texto_exemplo,\n",
        "            lang=idioma,\n",
        "            slow=False\n",
        "        )\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as f:\n",
        "            caminho_mp3 = f.name\n",
        "            tts.save(caminho_mp3)\n",
        "\n",
        "        # Converter MP3 para WAV, que √© mais comum para processamento em algumas libs\n",
        "        audio = AudioSegment.from_mp3(caminho_mp3)\n",
        "        caminho_wav = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\").name\n",
        "        audio.export(caminho_wav, format=\"wav\")\n",
        "\n",
        "        os.remove(caminho_mp3) # Remover arquivo mp3 tempor√°rio\n",
        "\n",
        "        print(f\"üéµ Arquivo de exemplo criado: {caminho_wav}\")\n",
        "        return caminho_wav\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao criar √°udio de exemplo com gTTS: {e}\")\n",
        "        return None\n",
        "\n",
        "# Testar com exemplo\n",
        "print(\"üéØ TESTE COMPLETO DO SISTEMA\")\n",
        "print(\"-\"*30)\n",
        "\n",
        "# Criar √°udio de exemplo\n",
        "audio_teste = criar_audio_exemplo()\n",
        "\n",
        "# Processar\n",
        "if audio_teste:\n",
        "    pergunta, resposta, audio = processar_audio(audio_teste)\n",
        "\n",
        "    print(\"\\nüìä RESULTADOS:\")\n",
        "    print(f\"Pergunta: {pergunta}\")\n",
        "    print(f\"Resposta: {resposta[:100]}...\")\n",
        "    print(f\"√Åudio resposta: {audio}\")\n",
        "else:\n",
        "    print(\"‚ùå N√£o foi poss√≠vel criar o √°udio de exemplo. Verifique os logs.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjWBsXjr0-cm",
        "outputId": "0b47c3bb-94df-46e9-95eb-6b9a2b04c741"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ TESTE COMPLETO DO SISTEMA\n",
            "------------------------------\n",
            "üéµ Arquivo de exemplo criado: /tmp/tmpmtnl469b.wav\n",
            "==================================================\n",
            "üîÑ PROCESSANDO √ÅUDIO...\n",
            "==================================================\n",
            "üé§ Transcrevendo √°udio... (idioma: pt)\n",
            "üìù Texto transcrito: Ol√°! Este √© um teste de √°udio para o assistente de voz.\n",
            "ü§ñ Enviando para ChatGPT...\n",
            "‚ùå Erro no ChatGPT: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************5jcA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}, 'status': 401}\n",
            "üîä Convertendo para voz (pt)...\n",
            "‚úÖ √Åudio salvo em: /tmp/tmpxt3jkr0o.mp3\n",
            "‚úÖ Processamento completo!\n",
            "\n",
            "üìä RESULTADOS:\n",
            "Pergunta: Ol√°! Este √© um teste de √°udio para o assistente de voz.\n",
            "Resposta: Desculpe, ocorreu um erro: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-p...\n",
            "√Åudio resposta: /tmp/tmpxt3jkr0o.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA 9: Interface Gradio simples\n",
        "def interface_web():\n",
        "    \"\"\"Cria interface web para upload de √°udio\"\"\"\n",
        "\n",
        "    def processar_interativo(audio_file, idioma):\n",
        "        if audio_file is None:\n",
        "            return \"Por favor, fa√ßa upload de um arquivo de √°udio\", None\n",
        "\n",
        "        pergunta, resposta, caminho_audio = processar_audio(\n",
        "            audio_file,\n",
        "            idioma_transcricao=idioma,\n",
        "            idioma_resposta=idioma\n",
        "        )\n",
        "\n",
        "        # Retornar resultados\n",
        "        resultados = f\"\"\"\n",
        "        **Pergunta transcrita:** {pergunta}\n",
        "\n",
        "        **Resposta do ChatGPT:** {resposta}\n",
        "        \"\"\"\n",
        "\n",
        "        return resultados, caminho_audio\n",
        "\n",
        "    # Criar interface\n",
        "    interface = gr.Interface(\n",
        "        fn=processar_interativo,\n",
        "        inputs=[\n",
        "            gr.Audio(sources=[\"upload\"], type=\"filepath\", label=\"Fa√ßa upload do seu √°udio\"),\n",
        "            gr.Dropdown(\n",
        "                choices=[\"pt\", \"en\", \"es\", \"fr\", \"de\"],\n",
        "                value=\"pt\",\n",
        "                label=\"Idioma do √°udio\"\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox(label=\"Resultados da Conversa\"),\n",
        "            gr.Audio(label=\"Resposta em Voz\", type=\"filepath\")\n",
        "        ],\n",
        "        title=\"‚ÄÅ Assistente de Voz com Whisper e ChatGPT\",\n",
        "        description=\"Fa√ßa upload de um arquivo de √°udio (WAV/MP3) e receba uma resposta por voz!\",\n",
        "        theme=\"soft\"\n",
        "    )\n",
        "\n",
        "    return interface\n",
        "\n",
        "print(\"üé® Interface criada. Execute a pr√≥xima c√©lula para lan√ßar.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlDHmDlw1BpN",
        "outputId": "bf9fdb43-a260-4045-8dc0-a109a2edc934"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé® Interface criada. Execute a pr√≥xima c√©lula para lan√ßar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA 10: Lan√ßar interface (execute esta c√©lula)\n",
        "print(\"üöÄ Iniciando interface web...\")\n",
        "# Certifique-se de que a C√âLULA 9 foi executada AP√ìS as √∫ltimas modifica√ß√µes para que a fun√ß√£o interface_web esteja atualizada.\n",
        "interface = interface_web()\n",
        "interface.launch(debug=True, share=False)  # Set share=True para link p√∫blico"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "cOFGPqwW1Ejl",
        "outputId": "ebd89a8a-433c-4867-886a-f9367c18bd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando interface web...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TnaeNBvB1HFY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}